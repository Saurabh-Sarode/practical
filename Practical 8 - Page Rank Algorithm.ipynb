{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47d3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(G, alpha=0.85, personalization=None, max_iter=100, tol=1.0e-6, nstart=None, weight='weight', dangling=None):\n",
    "    if len(G) == 0: \n",
    "        return {} \n",
    "  \n",
    "    if not G.is_directed(): \n",
    "        D = G.to_directed() \n",
    "    else: \n",
    "        D = G\n",
    "        \n",
    "    # Create a copy in (right) stochastic form \n",
    "    W = nx.stochastic_graph(D, weight=weight) \n",
    "    N = W.number_of_nodes()\n",
    "    \n",
    "    # Choose fixed starting vector if not given \n",
    "    if nstart is None: \n",
    "        x = dict.fromkeys(W, 1.0 / N) \n",
    "    else: \n",
    "        # Normalized nstart vector \n",
    "        s = float(sum(nstart.values())) \n",
    "        x = dict((k, v / s) for k, v in nstart.items()) \n",
    "        \n",
    "    if personalization is None:\n",
    "        # Assign uniform personalization vector if not given \n",
    "        p = dict.fromkeys(W, 1.0 / N)\n",
    "    else: \n",
    "        missing = set(G) - set(personalization) \n",
    "        if missing: \n",
    "            raise NetworkXError('Personalization dictionary must have a value for every node. Missing nodes %s' % missing) \n",
    "        s = float(sum(personalization.values())) \n",
    "        p = dict((k, v / s) for k, v in personalization.items())\n",
    "        \n",
    "    if dangling is None:\n",
    "        # Use personalization vector if dangling vector not specified \n",
    "        dangling_weights = p \n",
    "    else: \n",
    "        missing = set(G) - set(dangling) \n",
    "        if missing: \n",
    "            raise NetworkXError('Dangling node dictionary must have a value for every node. Missing nodes %s' % missing) \n",
    "        s = float(sum(dangling.values())) \n",
    "        dangling_weights = dict((k, v/s) for k, v in dangling.items())\n",
    "        \n",
    "    dangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0]\n",
    "    \n",
    "     # power iteration: make up to max_iter iterations \n",
    "    for _ in range(max_iter): \n",
    "        xlast = x \n",
    "        x = dict.fromkeys(xlast.keys(), 0) \n",
    "        danglesum = alpha * sum(xlast[n] for n in dangling_nodes) \n",
    "        for n in x:\n",
    "            # this matrix multiply looks odd because it is \n",
    "            # doing a left multiply x^T=xlast^T*W \n",
    "            for nbr in W[n]: \n",
    "                x[nbr] += alpha * xlast[n] * W[n][nbr][weight] \n",
    "            x[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n] \n",
    "  \n",
    "        # check convergence, l1 norm \n",
    "        err = sum([abs(x[n] - xlast[n]) for n in x]) \n",
    "        if err < N*tol: \n",
    "            return x \n",
    "    raise NetworkXError('Pagerank: power iteration failed to converge in %d iterations.' % max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f9359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f391812",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.barabasi_albert_graph(60, 41) \n",
    "pr = nx.pagerank(G, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76b3c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.028239119195940958, 1: 0.012774942020766726, 2: 0.01277911955291917, 3: 0.011583329230516855, 4: 0.012977000281773957, 5: 0.012560466982096414, 6: 0.013367351679289223, 7: 0.012361127799731066, 8: 0.013378444404555644, 9: 0.01337947013433502, 10: 0.013361016275672538, 11: 0.012164903923318706, 12: 0.012945755859407894, 13: 0.01357621968833211, 14: 0.012957500172750085, 15: 0.012971495425634161, 16: 0.01336157185076458, 17: 0.011964580577507548, 18: 0.013777186635263722, 19: 0.012983285155032808, 20: 0.012969599626064416, 21: 0.013777186635263722, 22: 0.012978389807142755, 23: 0.012968605201926654, 24: 0.011956961335029983, 25: 0.013565344205968798, 26: 0.012971830186845081, 27: 0.01316660197526072, 28: 0.012979310425323696, 29: 0.013165412547037339, 30: 0.012554971936859718, 31: 0.013160012333167933, 32: 0.013168027798359998, 33: 0.012975266289344563, 34: 0.012358537246070726, 35: 0.012742651128325008, 36: 0.011964459474898556, 37: 0.01275400672216797, 38: 0.013387981685420443, 39: 0.013573414280059504, 40: 0.013575404211081117, 41: 0.012966821227391942, 42: 0.027826721603092915, 43: 0.02750744044230543, 44: 0.027158360191055914, 45: 0.026679403801984136, 46: 0.026153814618654292, 47: 0.02596352412137272, 48: 0.025118776510912287, 49: 0.02498075251844998, 50: 0.024432437580102717, 51: 0.024226711990493935, 52: 0.02365885894933454, 53: 0.023612935275568958, 54: 0.02320433860761948, 55: 0.0224143387851731, 56: 0.022559852994121603, 57: 0.02200906768766956, 58: 0.021634695232599605, 59: 0.021713285964869086}\n"
     ]
    }
   ],
   "source": [
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439f3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
